{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd0373-6b48-48c2-af84-574d136a3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name - Bodke Sairaj Nivrutti.\n",
    "Class - T.E. AI & DS.\n",
    "Subject - Softwre lab II(317533)\n",
    "Roll No. - 06\n",
    "Assignment No.10 - Write a python program to implement CNN object detection. Discuss numerous Performance \n",
    "                   evaluation metrics for evaluating the object detecting alogorithms performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e41a1d-785f-42ff-adbf-e0be4d51dee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 52ms/step - accuracy: 0.2372 - loss: 2.0362 - val_accuracy: 0.4648 - val_loss: 1.4751\n",
      "Epoch 2/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77us/step - accuracy: 0.4062 - loss: 1.4775 - val_accuracy: 0.3750 - val_loss: 1.5976\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saira\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.4550 - loss: 1.5042 - val_accuracy: 0.5631 - val_loss: 1.2404\n",
      "Epoch 4/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.5625 - loss: 1.3750 - val_accuracy: 0.6250 - val_loss: 0.9728\n",
      "Epoch 5/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.5186 - loss: 1.3399 - val_accuracy: 0.6103 - val_loss: 1.0973\n",
      "Epoch 6/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.5312 - loss: 1.3749 - val_accuracy: 0.6875 - val_loss: 0.6930\n",
      "Epoch 7/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.5641 - loss: 1.2281 - val_accuracy: 0.6327 - val_loss: 1.0386\n",
      "Epoch 8/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.5312 - loss: 1.1881 - val_accuracy: 0.7500 - val_loss: 1.2100\n",
      "Epoch 9/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.5915 - loss: 1.1392 - val_accuracy: 0.6705 - val_loss: 0.9475\n",
      "Epoch 10/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.5938 - loss: 0.8976 - val_accuracy: 0.6875 - val_loss: 0.7179\n",
      "Epoch 11/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.6136 - loss: 1.1007 - val_accuracy: 0.6673 - val_loss: 0.9596\n",
      "Epoch 12/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.5312 - loss: 1.2561 - val_accuracy: 0.5625 - val_loss: 0.9781\n",
      "Epoch 13/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.6313 - loss: 1.0511 - val_accuracy: 0.7045 - val_loss: 0.8518\n",
      "Epoch 14/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.6250 - loss: 0.8821 - val_accuracy: 0.8125 - val_loss: 0.6170\n",
      "Epoch 15/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.6482 - loss: 1.0108 - val_accuracy: 0.7069 - val_loss: 0.8543\n",
      "Epoch 16/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.7500 - loss: 0.8161 - val_accuracy: 0.9375 - val_loss: 0.5786\n",
      "Epoch 17/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.6518 - loss: 0.9949 - val_accuracy: 0.7133 - val_loss: 0.8394\n",
      "Epoch 18/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.5625 - loss: 1.3398 - val_accuracy: 0.7500 - val_loss: 1.0011\n",
      "Epoch 19/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.6580 - loss: 0.9817 - val_accuracy: 0.6910 - val_loss: 0.8787\n",
      "Epoch 20/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31us/step - accuracy: 0.5312 - loss: 1.3973 - val_accuracy: 0.6875 - val_loss: 1.0445\n",
      "Epoch 21/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 55ms/step - accuracy: 0.6651 - loss: 0.9712 - val_accuracy: 0.7232 - val_loss: 0.8065\n",
      "Epoch 22/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.6875 - loss: 0.7534 - val_accuracy: 0.6875 - val_loss: 1.0706\n",
      "Epoch 23/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 64ms/step - accuracy: 0.6725 - loss: 0.9409 - val_accuracy: 0.7311 - val_loss: 0.7840\n",
      "Epoch 24/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.5938 - loss: 1.0590 - val_accuracy: 0.7500 - val_loss: 0.8429\n",
      "Epoch 25/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.6727 - loss: 0.9418 - val_accuracy: 0.7133 - val_loss: 0.8321\n",
      "Epoch 26/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.7500 - loss: 0.9123 - val_accuracy: 0.7500 - val_loss: 0.8744\n",
      "Epoch 27/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 53ms/step - accuracy: 0.6748 - loss: 0.9374 - val_accuracy: 0.7414 - val_loss: 0.7638\n",
      "Epoch 28/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43us/step - accuracy: 0.7500 - loss: 0.6646 - val_accuracy: 0.6875 - val_loss: 0.9849\n",
      "Epoch 29/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 57ms/step - accuracy: 0.6792 - loss: 0.9254 - val_accuracy: 0.7064 - val_loss: 0.8435\n",
      "Epoch 30/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.6250 - loss: 0.9784 - val_accuracy: 0.6875 - val_loss: 0.7909\n",
      "Epoch 31/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.6802 - loss: 0.9261 - val_accuracy: 0.7186 - val_loss: 0.8189\n",
      "Epoch 32/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.8125 - loss: 0.6319 - val_accuracy: 0.6250 - val_loss: 1.2143\n",
      "Epoch 33/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.6844 - loss: 0.9158 - val_accuracy: 0.7344 - val_loss: 0.7628\n",
      "Epoch 34/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.7500 - loss: 0.8856 - val_accuracy: 0.5625 - val_loss: 1.1545\n",
      "Epoch 35/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 57ms/step - accuracy: 0.6888 - loss: 0.9024 - val_accuracy: 0.7233 - val_loss: 0.8091\n",
      "Epoch 36/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41us/step - accuracy: 0.6875 - loss: 0.9190 - val_accuracy: 0.7500 - val_loss: 0.6725\n",
      "Epoch 37/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 56ms/step - accuracy: 0.6900 - loss: 0.8952 - val_accuracy: 0.7312 - val_loss: 0.7875\n",
      "Epoch 38/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.7812 - loss: 0.6801 - val_accuracy: 0.8125 - val_loss: 0.5461\n",
      "Epoch 39/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.6934 - loss: 0.8861 - val_accuracy: 0.7340 - val_loss: 0.7836\n",
      "Epoch 40/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.7188 - loss: 0.7940 - val_accuracy: 0.8750 - val_loss: 0.7003\n",
      "Epoch 41/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - accuracy: 0.6966 - loss: 0.8825 - val_accuracy: 0.6967 - val_loss: 0.8913\n",
      "Epoch 42/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.7188 - loss: 0.8735 - val_accuracy: 0.8750 - val_loss: 0.5242\n",
      "Epoch 43/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - accuracy: 0.6895 - loss: 0.8969 - val_accuracy: 0.7269 - val_loss: 0.8036\n",
      "Epoch 44/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.6250 - loss: 1.3549 - val_accuracy: 0.8750 - val_loss: 0.4874\n",
      "Epoch 45/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - accuracy: 0.6935 - loss: 0.8844 - val_accuracy: 0.7279 - val_loss: 0.7992\n",
      "Epoch 46/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.6562 - loss: 1.1125 - val_accuracy: 0.6250 - val_loss: 1.5567\n",
      "Epoch 47/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 58ms/step - accuracy: 0.6989 - loss: 0.8782 - val_accuracy: 0.7141 - val_loss: 0.8664\n",
      "Epoch 48/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.7500 - loss: 0.6990 - val_accuracy: 0.7500 - val_loss: 0.7006\n",
      "Epoch 49/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 56ms/step - accuracy: 0.6997 - loss: 0.8786 - val_accuracy: 0.7274 - val_loss: 0.8108\n",
      "Epoch 50/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.7812 - loss: 0.8714 - val_accuracy: 0.6875 - val_loss: 0.8605\n",
      "Epoch 51/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 55ms/step - accuracy: 0.7006 - loss: 0.8716 - val_accuracy: 0.7359 - val_loss: 0.7610\n",
      "Epoch 52/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.5312 - loss: 1.2995 - val_accuracy: 0.6250 - val_loss: 1.2365\n",
      "Epoch 53/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.6954 - loss: 0.8756 - val_accuracy: 0.7511 - val_loss: 0.7589\n",
      "Epoch 54/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.5938 - loss: 0.8353 - val_accuracy: 0.8125 - val_loss: 0.5828\n",
      "Epoch 55/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.6998 - loss: 0.8710 - val_accuracy: 0.7432 - val_loss: 0.7621\n",
      "Epoch 56/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.6875 - loss: 1.0621 - val_accuracy: 0.8750 - val_loss: 0.5728\n",
      "Epoch 57/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.6961 - loss: 0.8853 - val_accuracy: 0.7279 - val_loss: 0.8198\n",
      "Epoch 58/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40us/step - accuracy: 0.7188 - loss: 0.7185 - val_accuracy: 0.6875 - val_loss: 0.9493\n",
      "Epoch 59/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 55ms/step - accuracy: 0.6984 - loss: 0.8748 - val_accuracy: 0.7526 - val_loss: 0.7442\n",
      "Epoch 60/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.6875 - loss: 0.7241 - val_accuracy: 0.8750 - val_loss: 0.6171\n",
      "Epoch 61/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.7002 - loss: 0.8747 - val_accuracy: 0.7286 - val_loss: 0.7948\n",
      "Epoch 62/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34us/step - accuracy: 0.7500 - loss: 0.6146 - val_accuracy: 0.8750 - val_loss: 0.7966\n",
      "Epoch 63/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 56ms/step - accuracy: 0.6958 - loss: 0.8801 - val_accuracy: 0.7384 - val_loss: 0.7764\n",
      "Epoch 64/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45us/step - accuracy: 0.7500 - loss: 0.7603 - val_accuracy: 0.6250 - val_loss: 0.9859\n",
      "Epoch 65/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 55ms/step - accuracy: 0.7009 - loss: 0.8671 - val_accuracy: 0.7109 - val_loss: 0.8691\n",
      "Epoch 66/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.6562 - loss: 1.0947 - val_accuracy: 0.8125 - val_loss: 0.7844\n",
      "Epoch 67/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.7030 - loss: 0.8710 - val_accuracy: 0.7268 - val_loss: 0.7867\n",
      "Epoch 68/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.6875 - loss: 0.7964 - val_accuracy: 0.6250 - val_loss: 1.2553\n",
      "Epoch 69/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 55ms/step - accuracy: 0.7071 - loss: 0.8687 - val_accuracy: 0.7413 - val_loss: 0.7676\n",
      "Epoch 70/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.6875 - loss: 0.8550 - val_accuracy: 0.6250 - val_loss: 0.9312\n",
      "Epoch 71/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.7027 - loss: 0.8739 - val_accuracy: 0.7281 - val_loss: 0.7960\n",
      "Epoch 72/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.7188 - loss: 0.9757 - val_accuracy: 0.6875 - val_loss: 0.7836\n",
      "Epoch 73/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.7036 - loss: 0.8712 - val_accuracy: 0.7379 - val_loss: 0.7800\n",
      "Epoch 74/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.6562 - loss: 0.8722 - val_accuracy: 0.7500 - val_loss: 0.7116\n",
      "Epoch 75/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.7024 - loss: 0.8681 - val_accuracy: 0.7275 - val_loss: 0.8041\n",
      "Epoch 76/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.6562 - loss: 0.9644 - val_accuracy: 0.7500 - val_loss: 0.6300\n",
      "Epoch 77/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 56ms/step - accuracy: 0.7029 - loss: 0.8686 - val_accuracy: 0.7193 - val_loss: 0.8365\n",
      "Epoch 78/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.8125 - loss: 0.8519 - val_accuracy: 0.8125 - val_loss: 0.7144\n",
      "Epoch 79/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 55ms/step - accuracy: 0.7052 - loss: 0.8705 - val_accuracy: 0.7259 - val_loss: 0.8147\n",
      "Epoch 80/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33us/step - accuracy: 0.6875 - loss: 0.9009 - val_accuracy: 0.6875 - val_loss: 1.2916\n",
      "Epoch 81/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.7030 - loss: 0.8767 - val_accuracy: 0.7372 - val_loss: 0.7895\n",
      "Epoch 82/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.5938 - loss: 0.9716 - val_accuracy: 0.6250 - val_loss: 0.8242\n",
      "Epoch 83/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - accuracy: 0.7022 - loss: 0.8746 - val_accuracy: 0.7220 - val_loss: 0.8480\n",
      "Epoch 84/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.6562 - loss: 0.7595 - val_accuracy: 0.5625 - val_loss: 1.0428\n",
      "Epoch 85/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 56ms/step - accuracy: 0.7004 - loss: 0.8844 - val_accuracy: 0.7391 - val_loss: 0.8166\n",
      "Epoch 86/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.6875 - loss: 0.9995 - val_accuracy: 0.8750 - val_loss: 0.5767\n",
      "Epoch 87/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - accuracy: 0.7082 - loss: 0.8642 - val_accuracy: 0.7474 - val_loss: 0.7486\n",
      "Epoch 88/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.6250 - loss: 0.9498 - val_accuracy: 0.7500 - val_loss: 0.4868\n",
      "Epoch 89/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 56ms/step - accuracy: 0.7031 - loss: 0.8741 - val_accuracy: 0.7551 - val_loss: 0.7426\n",
      "Epoch 90/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.6562 - loss: 1.2466 - val_accuracy: 0.8750 - val_loss: 0.7712\n",
      "Epoch 91/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.7040 - loss: 0.8673 - val_accuracy: 0.7449 - val_loss: 0.7685\n",
      "Epoch 92/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.7188 - loss: 0.8455 - val_accuracy: 0.6250 - val_loss: 0.9219\n",
      "Epoch 93/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 55ms/step - accuracy: 0.7037 - loss: 0.8672 - val_accuracy: 0.7287 - val_loss: 0.8388\n",
      "Epoch 94/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32us/step - accuracy: 0.7812 - loss: 0.6595 - val_accuracy: 0.6875 - val_loss: 0.7341\n",
      "Epoch 95/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 60ms/step - accuracy: 0.7002 - loss: 0.8777 - val_accuracy: 0.7469 - val_loss: 0.7426\n",
      "Epoch 96/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.6250 - loss: 1.1057 - val_accuracy: 0.9375 - val_loss: 0.3769\n",
      "Epoch 97/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 58ms/step - accuracy: 0.7064 - loss: 0.8611 - val_accuracy: 0.6955 - val_loss: 0.9382\n",
      "Epoch 98/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38us/step - accuracy: 0.4688 - loss: 1.3483 - val_accuracy: 0.7500 - val_loss: 0.8789\n",
      "Epoch 99/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 60ms/step - accuracy: 0.6988 - loss: 0.8825 - val_accuracy: 0.7209 - val_loss: 0.8247\n",
      "Epoch 100/100\n",
      "\u001b[1m1562/1562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36us/step - accuracy: 0.7500 - loss: 0.6635 - val_accuracy: 0.8125 - val_loss: 0.3627\n",
      "Test loss: 0.8247584104537964\n",
      "Test accuracy: 0.7213000059127808\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Define data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Convert target values to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Prepare the data\n",
    "train_set = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "test_set = test_datagen.flow(X_test, y_test, batch_size=32)\n",
    "\n",
    "# Compile the model\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_set, steps_per_epoch=len(X_train)//32, epochs=100, validation_data=test_set, validation_steps=len(X_test)//32)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.evaluate(test_set, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb5a71-b53c-440d-9fed-818ac58e0744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
